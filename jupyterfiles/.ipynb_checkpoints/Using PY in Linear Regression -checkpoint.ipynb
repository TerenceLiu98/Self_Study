{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "\n",
    "## Introduction \n",
    "\n",
    "* 什麼是回歸，什麼是線性迴歸\n",
    "* 估計方法\n",
    "<a href = \"https://www.kdnuggets.com/2016/11/machine-learning-vs-statistics.html\"> Aatash Shah曾在他的文章中作过这样的定义：</a>\n",
    "\n",
    "> * “机器学习”是一种能够直接从数据中学习，而无需依赖规则编程的算法。\n",
    "\n",
    "> * “建立统计模型”的意思是以数学方程式来表示数据变量间的关系。\n",
    "\n",
    "實際上，機器學習的很多 fashion advanced 的算法都是基於線性回歸的，所以，在能夠跟進一步了解其他算法之前，我們需要好好了解一下甚麼是線性迴歸。\n",
    "\n",
    "### 什麼是回歸 \n",
    "\n",
    "在现实世界中存在大量这样的情况：两个或多个变量之间有一些联系，但是没有确切关系（没有确切到可以严格决定的程度），例如：人的身高$X$和體重$Y$有關係，一般表現為$X$增大時$Y$也傾向於增大，但由$X$並不能嚴格決定$Y$；一種農作物的畝產量$Y$與其播種量$X_1$、施肥量$X_2$，等等有關，但是$X Series$並不能嚴格確定$Y$。\n",
    "\n",
    "因此，根據上述例子，$Y$一般被稱為**因變量**或者回歸變量(regressand)，而$X$被稱為回歸量、自變量（independent variable, regressors)。\n",
    "\n",
    "為什麼$X$不能嚴格決定$Y$？很簡單，因為自變量太多了，而我們是無法窮盡（大部分情況）這些自變量，而且如果窮盡了這些自變量，很容易發生「過擬合」的情況(overfitted)；另外，$X$是那些跟$Y$有關的變量，而非絕對的因果關係，如果從英文中，我們可以很容易理解這個「關係」：correlation & causality. \n",
    "\n",
    "現在我們家者一個問題中有因變量$Y$以及自變量$X_1, X_2,\\dots, X_p$.可以設想$Y$的值由兩部分構成，一部分由$X_1, X_2,\\dots, X_p$的影響所導致，一部分是由未知因素導致，我們將第二部分歸咎為「誤差」(error)，這樣一來，我們就可以得到一個式子：\n",
    "$$Y = f(X) + \\epsilon \\ \\ \\ \\ X = (X_1, X_2,\\dots, X_p), \\ \\ \\epsilon = \\text{error}$$\n",
    "作為隨機誤差，我們要求它的期望為零：$\\displaystyle E(\\sum_i^p \\epsilon_i) = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線性迴歸 (Linear Regression)\n",
    "\n",
    "在這裏，我們只討論回歸函數$f(x)$為線型函數的情況（包括可以轉化成線性函數的情況），我們稱其為：線性迴歸(Linear Regression),在這一節，我們只討論簡單線性迴歸，就是一元線性迴歸(Simple Linear Regression)，我們只討論還有一個自變量$X$（因變量只有也只會有一個$Y$）。\n",
    "\n",
    "$\\begin{align*}\n",
    "    Y &=& \\beta_0 + \\beta_1 X + \\epsilon \\\\ \n",
    "    E(\\epsilon) = 0 \\ \\ \\ Var(\\epsilon) = \\sigma^2 \\\\\n",
    " \\end{align*}$\n",
    "where:\n",
    "\n",
    "* $x$: Independent variable(regressor);\n",
    "* $Y$: Dependent variable(response);\n",
    "* $\\epsilon$: Random error;\n",
    "* $\\beta_0, \\beta_1, \\sigma^2$: Unknown parameters;\n",
    "* $\\sigma^2$: Random error variance \n",
    "\n",
    "#### 估計方法 (Methods of Estimation) —— 點估計(Point Estimation) \n",
    "\n",
    "我們對模型的變量$X, Y$進行了$n$次獨立觀察，得樣本：\n",
    "$$(X_1, Y_1), (X_2, Y_2), \\dots, (X_n, Y_n)$$ \n",
    "\n",
    "這組樣本：$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\ \\ \\ i = (1,\\dots,n)$\n",
    "我們可以將樣本帶入方程中得出$p$個式子，每一個式子裡都會有一個隨機誤差。\n",
    "\n",
    "我們需要估計$\\beta_0$和$\\beta_1$\n",
    "\n",
    "##### 最小二乘法 (Least Square Estimiation) \n",
    "\n",
    "* 觀測點：$(X_1, Y_1), (X_2, Y_2), \\dots, (X_n, Y_n)$\n",
    "* 函數：$y_i \\beta_0 + \\beta_1 x_i + \\epsilon_i , \\ \\ \\ i = 1,\\dots, n$\n",
    "* $\\epsilon_i, \\dots, \\epsilon_n$ are i.i.d, $\\ E(\\epsilon) = 0, \\ \\ Var(\\epsilon_i) = \\sigma^2$ \n",
    "\n",
    "我們想要估計的是$\\beta_0, \\beta_1$和$\\sigma^2$，我們可以使用**最小二乘法**去進行估計。\n",
    "\n",
    "* 殘差：$e_i = y_i - \\hat{y_i}$;\n",
    "* $Y$的估計值：$\\hat{y_i} = \\hat{beta_0} + \\hat{beta_1}x_i$；\n",
    "* $\\beta_0$和$\\beta_1$ 的估計值：$\\hat{\\beta_0}$ 和 $\\hat{\\beta_1}$.\n",
    "\n",
    "使用最小二乘法的目的就是使得殘差最小化。\n",
    "\n",
    "$$\\displaystyle Q = \\sum_{i=1}^n e_i^2 = \\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1 x_i)^2$$\n",
    "\n",
    "For minimizeing $Q$ with respect to $\\beta_0$ and $\\beta_1$, take derivatives:\n",
    "\n",
    "$\\begin{align*}\n",
    "    &\\frac{\\partial Q}{\\partial \\beta_0} = -2\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1x_i) = 0 \\\\\n",
    "    &\\frac{\\partial Q}{\\partial \\beta_1} = -2\\sum_{i=1}^n (y_i -\\beta_0 -\\beta_1 x_i)x_i = 0 \\\\\n",
    "    &S_{XX} = \\sum_{i=1}^n (x_i - \\bar{x})^2 = \\sum_{i=1}^n x_i^2 - \\frac{1}{n}(\\sum_{i=1}^n x_i)^2 \\\\\n",
    "    &S_{XY} = \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) = \\sum_{i=1}^n x_i y_i - \\frac{1}{n}(\\sum_{i=1}^n x_i)(\\sum_{i=1}^n y_i) \\\\\n",
    "  \\end{align*}$\n",
    "$\\Rightarrow \n",
    "    \\begin{equation}\n",
    "        \\left\\{\n",
    "             \\begin{array}{lr}\n",
    "                 \\hat{\\beta_1} = S_{XY} / S_{XX} \\\\\n",
    "                 \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} \\bar{x} \\\\\n",
    "              \\end{array}\n",
    "        \\right.\n",
    "    \\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
